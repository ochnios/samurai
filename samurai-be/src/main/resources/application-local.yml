server:
  port: 8080

spring:
  servlet:
    multipart:
      max-file-size: 50MB
      max-request-size: 50MB
  mvc:
    log-request-details: true
  datasource:
    driverClassName: org.postgresql.Driver
    url: jdbc:postgresql://${PRIMARY_DB_HOST}:${PRIMARY_DB_PORT}/${PRIMARY_DB_NAME}
    username: ${PRIMARY_DB_USER}
    password: ${PRIMARY_DB_PASSWORD}
  jpa:
    hibernate:
      ddl-auto: update
    properties:
      hibernate:
        format_sql: false
        dialect: org.hibernate.dialect.PostgreSQLDialect
    open-in-view: true
  h2:
    console:
      enabled: true
  # Important note: Only one ChatModel have to be available in application context
  # You can disable unused chat models using its 'enable' flag or by excluding model autoconfiguration
  # After switching models it may be necessary to customize ChatClientProvider
  ai:
    vectorstore:
      qdrant:
        host: ${QDRANT_HOST}
        port: ${QDRANT_PORT}
        initialize-schema: true
        collection-name: documents
    openai:
      api-key: ${OPENAI_API_KEY}
      embedding:
        enabled: true
        options:
          model: text-embedding-3-large
          dimensions: 3072
      chat:
        enabled: true
      image:
        enabled: false
      audio:
        speech:
          enabled: false
        transcription:
          enabled: false
    anthropic:
      chat:
        enabled: false

logging:
  level:
    pl:
      ochnios:
        samurai: DEBUG
    org:
      springframework:
        web: DEBUG
        security: DEBUG
        ai: INFO
      hibernate:
        SQL: DEBUG
        type:
          descriptor:
            sql:
              BasicBinder: TRACE

custom:
  loader:
    enabled: true
    bulk: false
  chunking:
    enabled: true
    initialDelay:
      seconds: 15
    fixedDelay:
      seconds: 5
    maxChunkLength: 5000
    minChunkLength: 300
  allowed-origins: http://localhost:5173,http://localhost,https://localhost
  jwt:
    passphrase: ${JWT_PASSPHRASE}
    expiration: 8h
    cookie:
      name: Authorization
      secure: false
      httpOnly: true
      prefix: Bearer_
      acceptAsHeader: true
      headerPrefix: "Bearer "
  # Note that both models have to be from single provider
  # https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb
  chat:
    model: gpt-4o
    tokenEncoding: o200k_base
    maxDocumentTokens: 32000
    maxMessageTokens: 2000
  task:
    model: gpt-4o-mini
  search:
    topK: 5
    similarityThreshold: 0.5
